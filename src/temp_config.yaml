data:
  batch_size: 512
  normalize_position: true
  num_workers: 4
  test_size: 0.2
  use_transforms: false
experiment_id: 1
logging:
  info_prints: true
  log_freq: 20
  log_plot_freq: 1000
  wandb: false
model:
  attention_dropout: 0.0
  dropout: 0.0
  ensemble:
    num_models: 2
    use_best: false
  hidden_dim: 16
  mlp_dim: 64
  n_scales: 8
  num_heads: 4
  num_layers: 4
  patch_size: 5
  positive_eng: true
  positive_pos: true
  remove_batch_norm: false
  tag: SumModel
  use_checkpoint: 'no'
paths:
  best_checkpoint: best.pth.tar
  checkpoint: checkpoint.pth.tar
  checkpoint_dir: checkpoints
  data_dir: data_numpy
  data_file: 64k_wpc_10x10_v2.npz
training:
  eng_loss_weight: 0.5
  loss_fn_eng: RMSE_E
  loss_fn_pos: RMSE
  num_epochs: 100
  optimizer:
    learning_rate: 0.007
    tag: AdamW
    weight_decay: 0
  scheduler:
    gamma: 0.8
    step_size: 20
    tag: WarmupCosineSchedule
    warmup_steps: 15
  use_amp: false
