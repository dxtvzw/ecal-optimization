---
  logging:
    log_freq: 20
    log_plot_freq: 50
    info_prints: true
    wandb: false

  paths:
    # data_dir: "data"
    # data_file: "0001_64k_real_spectra_15x15_spot.root"
    # data_file: "0001_500k_real_spectra_15x15_spot.root"
    # data_file: "0001_64k_wpc_10x10_spot.root"
    # data_file: "0001_64k_wpc_10x10_spot_v2.root"
    # data_file: "0001_64k_wpc_15x15_spot.root"
    # data_file: "0001_64k_wpc_20x20_spot.root"
    # data_file: "0001_64k_wpc_25x25_spot_rs42.root"
    # data_file: "0001_64k_wpc_30x30_spot_rs42.root"
    # data_file: "0001_64k_wpc_40x40_spot_rs42.root"

    data_dir: "data_numpy"
    # data_file: "64k_real_15x15.npz"
    # data_file: "500k_real_15x15.npz"
    # data_file: "64k_wpc_10x10.npz"
    data_file: "64k_wpc_10x10_v2.npz"
    # data_file: "64k_wpc_15x15.npz"
    # data_file: "64k_wpc_20x20.npz"
    # data_file: "64k_wpc_25x25.npz"
    # data_file: "64k_wpc_30x30.npz"
    # data_file: "64k_wpc_40x40.npz"

    checkpoint_dir: "checkpoints"
    checkpoint: "checkpoint.pth.tar"
    best_checkpoint: "best.pth.tar"
  
  data:
    batch_size: 512
    num_workers: 4
    test_size: 0.2
    use_transforms: false
    normalize_position: true
  
  model:
    tag: "MyViT"
    use_checkpoint: "no" # one of "no", "last", "best"
    positive_eng: true
    positive_pos: false

    n_scales: 8
    hidden_dim: 16
    dropout: 0.0
    remove_batch_norm: false

    patch_size: 5
    num_layers: 4
    num_heads: 4
    mlp_dim: 64
    attention_dropout: 0.0

    ensemble:
      num_models: 2
      use_best: false
  
  training:
    num_epochs: 300
    use_amp: false

    optimizer:
      tag: "AdamW"
      learning_rate: 0.007
      weight_decay: 0

    scheduler:
      tag: "WarmupCosineSchedule"
      step_size: 20
      gamma: 0.8
      warmup_steps: 20

    loss_fn_eng: "RMSE_E" # one of "RMSE_E", "MAE_E", "MSE", "MAE", "RMSLE", "None"
    loss_fn_pos: "RMSE"
    eng_loss_weight: 1.0
